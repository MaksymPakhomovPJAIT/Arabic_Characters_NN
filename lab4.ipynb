{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Пахомов Максим КА-12 КП-4 \n",
    "# Вар-4 Arabic Handwritten Characters Dataset, kaggle.com"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9261c1e269f443cf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the basic model with one convolutional layer and tuning hyperparameters:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98c383768364283a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:43:31.843627Z",
     "start_time": "2025-03-17T10:40:54.545108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with padding=valid and strides=(1, 1)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:41:04.696991: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 2s 12ms/step - loss: 4.5071 - accuracy: 0.0935 - val_loss: 3.0112 - val_accuracy: 0.1291\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 2.8415 - accuracy: 0.1689 - val_loss: 2.6677 - val_accuracy: 0.2273\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 2.4707 - accuracy: 0.2546 - val_loss: 2.3379 - val_accuracy: 0.2734\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 2.0396 - accuracy: 0.3426 - val_loss: 1.9290 - val_accuracy: 0.4137\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 1.5055 - accuracy: 0.5042 - val_loss: 1.4171 - val_accuracy: 0.5301\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 1.0008 - accuracy: 0.6605 - val_loss: 1.1574 - val_accuracy: 0.6369\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.6881 - accuracy: 0.7621 - val_loss: 1.0120 - val_accuracy: 0.6879\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.5053 - accuracy: 0.8219 - val_loss: 0.9609 - val_accuracy: 0.7251\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.3796 - accuracy: 0.8676 - val_loss: 0.9408 - val_accuracy: 0.7281\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2963 - accuracy: 0.8946 - val_loss: 0.9412 - val_accuracy: 0.7530\n",
      "Validation accuracy: 0.7530\n",
      "\n",
      "Experiment with padding=same and strides=(1, 1)\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 4.4410 - accuracy: 0.1086 - val_loss: 2.9239 - val_accuracy: 0.1328\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 2.6213 - accuracy: 0.2349 - val_loss: 2.3463 - val_accuracy: 0.3173\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 1.9767 - accuracy: 0.3913 - val_loss: 1.7570 - val_accuracy: 0.4643\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 1.2639 - accuracy: 0.5927 - val_loss: 1.1835 - val_accuracy: 0.6220\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.7563 - accuracy: 0.7440 - val_loss: 0.9267 - val_accuracy: 0.7158\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.4826 - accuracy: 0.8414 - val_loss: 0.8521 - val_accuracy: 0.7511\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3301 - accuracy: 0.8894 - val_loss: 0.8595 - val_accuracy: 0.7589\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2332 - accuracy: 0.9255 - val_loss: 0.8410 - val_accuracy: 0.7679\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1544 - accuracy: 0.9515 - val_loss: 0.8598 - val_accuracy: 0.7753\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1155 - accuracy: 0.9661 - val_loss: 0.9290 - val_accuracy: 0.7786\n",
      "Validation accuracy: 0.7786\n",
      "\n",
      "Experiment with padding=same and strides=(2, 2)\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.8405 - accuracy: 0.2249 - val_loss: 2.2793 - val_accuracy: 0.3568\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.6364 - accuracy: 0.5027 - val_loss: 1.5189 - val_accuracy: 0.5420\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.9385 - accuracy: 0.6947 - val_loss: 1.1402 - val_accuracy: 0.6540\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.5879 - accuracy: 0.8057 - val_loss: 1.0483 - val_accuracy: 0.6868\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3915 - accuracy: 0.8686 - val_loss: 1.0029 - val_accuracy: 0.7113\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.2672 - accuracy: 0.9102 - val_loss: 1.0055 - val_accuracy: 0.7161\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 0.1828 - accuracy: 0.9395 - val_loss: 1.0243 - val_accuracy: 0.7366\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.1237 - accuracy: 0.9627 - val_loss: 1.0623 - val_accuracy: 0.7351\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9741 - val_loss: 1.1392 - val_accuracy: 0.7411\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.0695 - accuracy: 0.9792 - val_loss: 1.1471 - val_accuracy: 0.7478\n",
      "Validation accuracy: 0.7478\n",
      "\n",
      "Experiment with conv_layers=2, use_batch_norm=False, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 2.8516 - accuracy: 0.3547 - val_loss: 1.1891 - val_accuracy: 0.6235\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.8135 - accuracy: 0.7391 - val_loss: 0.7365 - val_accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.4068 - accuracy: 0.8690 - val_loss: 0.6079 - val_accuracy: 0.8054\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2353 - accuracy: 0.9224 - val_loss: 0.5112 - val_accuracy: 0.8516\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.1385 - accuracy: 0.9564 - val_loss: 0.5802 - val_accuracy: 0.8426\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.0911 - accuracy: 0.9701 - val_loss: 0.5371 - val_accuracy: 0.8586\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.0599 - accuracy: 0.9808 - val_loss: 0.5430 - val_accuracy: 0.8650\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.0544 - accuracy: 0.9808 - val_loss: 0.5908 - val_accuracy: 0.8672\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.0594 - accuracy: 0.9807 - val_loss: 0.6428 - val_accuracy: 0.8542\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.0522 - accuracy: 0.9820 - val_loss: 0.6674 - val_accuracy: 0.8560\n",
      "Validation accuracy: 0.8560\n",
      "\n",
      "Experiment with conv_layers=3, use_batch_norm=True, dropout_rate=0.2\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 4s 21ms/step - loss: 2.0497 - accuracy: 0.3870 - val_loss: 1.0714 - val_accuracy: 0.6574\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 3s 21ms/step - loss: 0.8133 - accuracy: 0.7358 - val_loss: 0.5569 - val_accuracy: 0.8203\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 4s 22ms/step - loss: 0.5023 - accuracy: 0.8331 - val_loss: 0.3856 - val_accuracy: 0.8694\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 4s 21ms/step - loss: 0.3604 - accuracy: 0.8829 - val_loss: 0.3694 - val_accuracy: 0.8709\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 4s 25ms/step - loss: 0.2836 - accuracy: 0.9082 - val_loss: 0.3029 - val_accuracy: 0.9022\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.2178 - accuracy: 0.9263 - val_loss: 0.2906 - val_accuracy: 0.9036\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.1884 - accuracy: 0.9398 - val_loss: 0.2916 - val_accuracy: 0.9003\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.1537 - accuracy: 0.9498 - val_loss: 0.2641 - val_accuracy: 0.9133\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.1358 - accuracy: 0.9551 - val_loss: 0.2731 - val_accuracy: 0.9107\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.1120 - accuracy: 0.9632 - val_loss: 0.2853 - val_accuracy: 0.9074\n",
      "Validation accuracy: 0.9074\n",
      "\n",
      "Experiment with conv_layers=3, use_batch_norm=True, dropout_rate=0.5\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 4s 23ms/step - loss: 2.5471 - accuracy: 0.2694 - val_loss: 1.3111 - val_accuracy: 0.5897\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 1.2824 - accuracy: 0.5875 - val_loss: 0.7241 - val_accuracy: 0.7805\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 4s 21ms/step - loss: 0.8346 - accuracy: 0.7255 - val_loss: 0.5698 - val_accuracy: 0.8233\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 4s 22ms/step - loss: 0.6290 - accuracy: 0.7932 - val_loss: 0.3796 - val_accuracy: 0.8780\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.5063 - accuracy: 0.8351 - val_loss: 0.3425 - val_accuracy: 0.8862\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.4257 - accuracy: 0.8614 - val_loss: 0.3028 - val_accuracy: 0.8999\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.3576 - accuracy: 0.8794 - val_loss: 0.2898 - val_accuracy: 0.9018\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.3244 - accuracy: 0.8928 - val_loss: 0.2577 - val_accuracy: 0.9129\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.2826 - accuracy: 0.9086 - val_loss: 0.2630 - val_accuracy: 0.9141\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.2568 - accuracy: 0.9149 - val_loss: 0.2361 - val_accuracy: 0.9215\n",
      "Validation accuracy: 0.9215\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# Importing data\n",
    "train_images = pd.read_csv('archive/csvTrainImages 13440x1024.csv', header=None)\n",
    "train_labels = pd.read_csv('archive/csvTrainLabel 13440x1.csv', header=None)\n",
    "test_images = pd.read_csv('archive/csvTestImages 3360x1024.csv', header=None)\n",
    "test_labels = pd.read_csv('archive/csvTestLabel 3360x1.csv', header=None)\n",
    "\n",
    "# Data preparation\n",
    "train_images = train_images.values.reshape(-1, 32, 32, 1).astype('float32')\n",
    "test_images = test_images.values.reshape(-1, 32, 32, 1).astype('float32')\n",
    "\n",
    "train_labels -= 1\n",
    "test_labels -= 1\n",
    "\n",
    "\n",
    "num_classes = 28 \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
    "\n",
    "# Splitting data into train/test\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function for building and training the model\n",
    "def build_and_train_model(conv_layers=1, filters=32, kernel_size=(3, 3), padding='valid', strides=(1, 1),\n",
    "                          use_batch_norm=False, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "\n",
    "    \n",
    "    for _ in range(conv_layers):\n",
    "        model.add(Conv2D(filters, kernel_size=kernel_size, padding=padding, strides=strides, activation='relu', input_shape=(32, 32, 1)))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # TensorBoard log\n",
    "    log_dir = \"logs/fit/\" + \"conv_layers\" + str(conv_layers) + \"use_batch_norm=\" + str(use_batch_norm) + \"dropout_rate\" + str(dropout_rate) + \"padding\" + str(padding) + \"strides\" + str(strides)\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Training a base model with 1 convolutional layer\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64, callbacks=[tensorboard_callback])\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Experiment 1: Different padding and strides\n",
    "params = [\n",
    "    {'padding': 'valid', 'strides': (1, 1)},\n",
    "    {'padding': 'same', 'strides': (1, 1)},\n",
    "    {'padding': 'same', 'strides': (2, 2)},\n",
    "]\n",
    "\n",
    "for param in params:\n",
    "    print(f\"Experiment with padding={param['padding']} and strides={param['strides']}\")\n",
    "    model, history = build_and_train_model(padding=param['padding'], strides=param['strides'])\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f'Validation accuracy: {val_acc:.4f}\\n')\n",
    "\n",
    "# Experiment 2: Alternative structures with different numbers of convolutional layers, normalisation and dropout\n",
    "architectures = [\n",
    "    {'conv_layers': 2, 'use_batch_norm': False, 'dropout_rate': 0.0},\n",
    "    {'conv_layers': 3, 'use_batch_norm': True, 'dropout_rate': 0.2},\n",
    "    {'conv_layers': 3, 'use_batch_norm': True, 'dropout_rate': 0.5},\n",
    "]\n",
    "\n",
    "for arch in architectures:\n",
    "    print(f\"Experiment with conv_layers={arch['conv_layers']}, use_batch_norm={arch['use_batch_norm']}, dropout_rate={arch['dropout_rate']}\")\n",
    "    model, history = build_and_train_model(conv_layers=arch['conv_layers'], use_batch_norm=arch['use_batch_norm'], dropout_rate=arch['dropout_rate'])\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f'Validation accuracy: {val_acc:.4f}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the best result in terms of metrics is the one with padding=same, strides=(1,1). This model has an accuracy of roughly 78%.\n",
    "Also after analysis of parameters and convolutional numbers analysis we can see that best parameters are 3 conv layers, 'use_batch_norm': True, 'dropout_rate': 0.2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10f157fde6dbf270"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's train such model and check the results:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8faf5069077f9a92"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:43:32.002982Z",
     "start_time": "2025-03-17T10:43:31.843007Z"
    }
   },
   "id": "828e70a410619ca8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "168/168 [==============================] - 5s 26ms/step - loss: 1.9304 - accuracy: 0.4243 - val_loss: 0.8334 - val_accuracy: 0.7344\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.6538 - accuracy: 0.7833 - val_loss: 0.4360 - val_accuracy: 0.8519\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 5s 27ms/step - loss: 0.3972 - accuracy: 0.8670 - val_loss: 0.3370 - val_accuracy: 0.8862\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 5s 27ms/step - loss: 0.2857 - accuracy: 0.9062 - val_loss: 0.2874 - val_accuracy: 0.9033\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.2081 - accuracy: 0.9289 - val_loss: 0.2843 - val_accuracy: 0.9100\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.1682 - accuracy: 0.9430 - val_loss: 0.2583 - val_accuracy: 0.9152\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 5s 28ms/step - loss: 0.1365 - accuracy: 0.9526 - val_loss: 0.2550 - val_accuracy: 0.9204\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 5s 27ms/step - loss: 0.1027 - accuracy: 0.9675 - val_loss: 0.2225 - val_accuracy: 0.9293\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.0969 - accuracy: 0.9667 - val_loss: 0.2240 - val_accuracy: 0.9342\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 4s 27ms/step - loss: 0.0779 - accuracy: 0.9747 - val_loss: 0.2352 - val_accuracy: 0.9271\n",
      "Test accuracy: 0.9265\n",
      "105/105 [==============================] - 1s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9754    0.9917    0.9835       120\n",
      "           1     0.9750    0.9750    0.9750       120\n",
      "           2     0.9570    0.7417    0.8357       120\n",
      "           3     0.8425    0.8917    0.8664       120\n",
      "           4     0.9810    0.8583    0.9156       120\n",
      "           5     0.8981    0.8083    0.8509       120\n",
      "           6     0.7724    0.9333    0.8453       120\n",
      "           7     0.9545    0.8750    0.9130       120\n",
      "           8     0.9375    0.8750    0.9052       120\n",
      "           9     0.8931    0.9750    0.9323       120\n",
      "          10     0.9244    0.9167    0.9205       120\n",
      "          11     0.9587    0.9667    0.9627       120\n",
      "          12     0.9831    0.9667    0.9748       120\n",
      "          13     0.9286    0.9750    0.9512       120\n",
      "          14     0.9417    0.9417    0.9417       120\n",
      "          15     0.9580    0.9500    0.9540       120\n",
      "          16     0.9421    0.9500    0.9461       120\n",
      "          17     0.8540    0.9750    0.9105       120\n",
      "          18     0.9474    0.9000    0.9231       120\n",
      "          19     0.8880    0.9250    0.9061       120\n",
      "          20     0.8346    0.8833    0.8583       120\n",
      "          21     0.9516    0.9833    0.9672       120\n",
      "          22     0.9750    0.9750    0.9750       120\n",
      "          23     0.9835    0.9917    0.9876       120\n",
      "          24     0.8934    0.9083    0.9008       120\n",
      "          25     0.9910    0.9167    0.9524       120\n",
      "          26     0.9120    0.9500    0.9306       120\n",
      "          27     0.9658    0.9417    0.9536       120\n",
      "\n",
      "    accuracy                         0.9265      3360\n",
      "   macro avg     0.9293    0.9265    0.9264      3360\n",
      "weighted avg     0.9293    0.9265    0.9264      3360\n",
      "\n",
      "AUC: 0.9987\n"
     ]
    }
   ],
   "source": [
    "best_model = build_and_train_model(conv_layers=3, use_batch_norm=True, dropout_rate=0.2, padding='same', strides=(1,1))[0]\n",
    "\n",
    "# Evalutating\n",
    "test_loss, test_acc = best_model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Getting metrics\n",
    "y_pred = best_model.predict(test_images)\n",
    "y_true = np.argmax(test_labels, axis=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes, digits=4))\n",
    "print(f\"AUC: {roc_auc_score(test_labels, y_pred, multi_class='ovr'):.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:44:18.692836Z",
     "start_time": "2025-03-17T10:43:32.008305Z"
    }
   },
   "id": "8a64df4a8a6ff77a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For all 28 classes we've got great metrics - good result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ae7cd5257c25a92"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:44:18.697140Z",
     "start_time": "2025-03-17T10:44:18.689515Z"
    }
   },
   "id": "c7615b12d801d1c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualisation of training in TensorBoard"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26dc8fea4e0cdb6d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:44:22.260154Z",
     "start_time": "2025-03-17T10:44:18.695395Z"
    }
   },
   "id": "55c4aa9fac67331f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now let's train the model on "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab27fecdc34111bc"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def load():\n",
    "    data = np.load(\"../data.npz\")\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    X_val = data['X_val']\n",
    "    y_val = data['y_val']\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "    return X_train,y_train,X_val,y_val,X_test,y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:44:22.270146Z",
     "start_time": "2025-03-17T10:44:22.263569Z"
    }
   },
   "id": "d2aa2acc4ccdc27"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_train,y_train,X_val,y_val,X_test,y_test=load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:44:22.318137Z",
     "start_time": "2025-03-17T10:44:22.268026Z"
    }
   },
   "id": "d85caca181c00365"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 64, 64, 1)\n",
    "X_val = X_val.reshape(-1, 64, 64, 1)\n",
    "X_test = X_test.reshape(-1, 64, 64, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:44:22.323150Z",
     "start_time": "2025-03-17T10:44:22.318508Z"
    }
   },
   "id": "6f552a08990285e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Робимо все те ж саме що і до цього, але тепер у вхідних та вихідних даних інший розмір, тому трохи змінимо функцію"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93d4fcccd6f2fb00"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with padding=valid and strides=(1, 1)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 6s 39ms/step - loss: 3.8772 - accuracy: 0.2427 - val_loss: 1.9236 - val_accuracy: 0.3913\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 6s 38ms/step - loss: 1.5165 - accuracy: 0.4990 - val_loss: 1.3205 - val_accuracy: 0.5804\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 6s 38ms/step - loss: 0.7533 - accuracy: 0.7447 - val_loss: 0.7423 - val_accuracy: 0.7875\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 6s 40ms/step - loss: 0.3360 - accuracy: 0.8915 - val_loss: 0.5394 - val_accuracy: 0.8479\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 6s 38ms/step - loss: 0.1516 - accuracy: 0.9536 - val_loss: 0.5573 - val_accuracy: 0.8654\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 6s 38ms/step - loss: 0.0775 - accuracy: 0.9797 - val_loss: 0.5381 - val_accuracy: 0.8754\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 6s 38ms/step - loss: 0.0467 - accuracy: 0.9895 - val_loss: 0.5577 - val_accuracy: 0.8808\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 6s 38ms/step - loss: 0.0275 - accuracy: 0.9960 - val_loss: 0.6003 - val_accuracy: 0.8825\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 6s 38ms/step - loss: 0.0176 - accuracy: 0.9971 - val_loss: 0.6232 - val_accuracy: 0.8871\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 6s 38ms/step - loss: 0.0104 - accuracy: 0.9989 - val_loss: 0.6357 - val_accuracy: 0.8896\n",
      "Validation accuracy: 0.8896\n",
      "\n",
      "Experiment with padding=same and strides=(1, 1)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 6s 41ms/step - loss: 2.9566 - accuracy: 0.3531 - val_loss: 1.2789 - val_accuracy: 0.5979\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 6s 43ms/step - loss: 0.7770 - accuracy: 0.7477 - val_loss: 0.6122 - val_accuracy: 0.8175\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 6s 40ms/step - loss: 0.3225 - accuracy: 0.8967 - val_loss: 0.5034 - val_accuracy: 0.8462\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 6s 40ms/step - loss: 0.1436 - accuracy: 0.9575 - val_loss: 0.4323 - val_accuracy: 0.8746\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 6s 40ms/step - loss: 0.0827 - accuracy: 0.9756 - val_loss: 0.4487 - val_accuracy: 0.8842\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 6s 39ms/step - loss: 0.0402 - accuracy: 0.9919 - val_loss: 0.4439 - val_accuracy: 0.8929\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 6s 39ms/step - loss: 0.0199 - accuracy: 0.9964 - val_loss: 0.4720 - val_accuracy: 0.8938\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 6s 40ms/step - loss: 0.0151 - accuracy: 0.9975 - val_loss: 0.4939 - val_accuracy: 0.8954\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 6s 40ms/step - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.5329 - val_accuracy: 0.9025\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 6s 40ms/step - loss: 0.0336 - accuracy: 0.9911 - val_loss: 0.7489 - val_accuracy: 0.8633\n",
      "Validation accuracy: 0.8633\n",
      "\n",
      "Experiment with padding=same and strides=(2, 2)\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 1.7060 - accuracy: 0.5238 - val_loss: 0.7951 - val_accuracy: 0.7567\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.4538 - accuracy: 0.8580 - val_loss: 0.5370 - val_accuracy: 0.8396\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.1778 - accuracy: 0.9481 - val_loss: 0.4593 - val_accuracy: 0.8746\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.0881 - accuracy: 0.9755 - val_loss: 0.4410 - val_accuracy: 0.8867\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.0419 - accuracy: 0.9916 - val_loss: 0.4670 - val_accuracy: 0.8917\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.0234 - accuracy: 0.9952 - val_loss: 0.4559 - val_accuracy: 0.8979\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 0.4794 - val_accuracy: 0.9046\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.4772 - val_accuracy: 0.9046\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 2s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.9033\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 2s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.9038\n",
      "Validation accuracy: 0.9038\n",
      "\n",
      "Experiment with conv_layers=2, use_batch_norm=False, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.3009 - accuracy: 0.6609 - val_loss: 0.4403 - val_accuracy: 0.8604\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 0.2273 - accuracy: 0.9293 - val_loss: 0.2776 - val_accuracy: 0.9217\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 0.0909 - accuracy: 0.9711 - val_loss: 0.2570 - val_accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 7s 50ms/step - loss: 0.0614 - accuracy: 0.9812 - val_loss: 0.3013 - val_accuracy: 0.9296\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 7s 48ms/step - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.2559 - val_accuracy: 0.9458\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 28s 191ms/step - loss: 0.0310 - accuracy: 0.9924 - val_loss: 0.3788 - val_accuracy: 0.9175\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 8s 53ms/step - loss: 0.0545 - accuracy: 0.9847 - val_loss: 0.3567 - val_accuracy: 0.9242\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 0.0510 - accuracy: 0.9849 - val_loss: 0.2805 - val_accuracy: 0.9450\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.2766 - val_accuracy: 0.9479\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.3197 - val_accuracy: 0.9421\n",
      "Validation accuracy: 0.9421\n",
      "\n",
      "Experiment with conv_layers=3, use_batch_norm=True, dropout_rate=0.2\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 12s 77ms/step - loss: 1.0078 - accuracy: 0.6816 - val_loss: 0.4670 - val_accuracy: 0.8492\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 11s 76ms/step - loss: 0.2392 - accuracy: 0.9217 - val_loss: 0.1785 - val_accuracy: 0.9463\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.1285 - accuracy: 0.9577 - val_loss: 0.1361 - val_accuracy: 0.9613\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 12s 79ms/step - loss: 0.0745 - accuracy: 0.9769 - val_loss: 0.1224 - val_accuracy: 0.9679\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 12s 80ms/step - loss: 0.0563 - accuracy: 0.9807 - val_loss: 0.0921 - val_accuracy: 0.9758\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 13s 85ms/step - loss: 0.0401 - accuracy: 0.9877 - val_loss: 0.1010 - val_accuracy: 0.9704\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.1003 - val_accuracy: 0.9771\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.0242 - accuracy: 0.9932 - val_loss: 0.0951 - val_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.1443 - val_accuracy: 0.9617\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 12s 82ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.1466 - val_accuracy: 0.9679\n",
      "Validation accuracy: 0.9679\n",
      "\n",
      "Experiment with conv_layers=3, use_batch_norm=True, dropout_rate=0.5\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 12s 76ms/step - loss: 1.5967 - accuracy: 0.5076 - val_loss: 0.5753 - val_accuracy: 0.8379\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 10s 70ms/step - loss: 0.5232 - accuracy: 0.8249 - val_loss: 0.2244 - val_accuracy: 0.9325\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 0.2998 - accuracy: 0.9024 - val_loss: 0.1461 - val_accuracy: 0.9550\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 0.2106 - accuracy: 0.9276 - val_loss: 0.1230 - val_accuracy: 0.9646\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 0.1412 - accuracy: 0.9527 - val_loss: 0.1681 - val_accuracy: 0.9496\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 10s 68ms/step - loss: 0.1207 - accuracy: 0.9627 - val_loss: 0.0822 - val_accuracy: 0.9792\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 12s 81ms/step - loss: 0.0931 - accuracy: 0.9679 - val_loss: 0.0879 - val_accuracy: 0.9783\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.0788 - accuracy: 0.9740 - val_loss: 0.1386 - val_accuracy: 0.9629\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 12s 78ms/step - loss: 0.0690 - accuracy: 0.9765 - val_loss: 0.0802 - val_accuracy: 0.9792\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 0.0607 - accuracy: 0.9807 - val_loss: 0.0858 - val_accuracy: 0.9804\n",
      "Validation accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "# Функція для побудови та навчання моделі\n",
    "def build_and_train_model_2(conv_layers=1, filters=32, kernel_size=(3, 3), padding='valid', strides=(1, 1),\n",
    "                          use_batch_norm=False, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    for _ in range(conv_layers):\n",
    "        model.add(Conv2D(filters, kernel_size=kernel_size, padding=padding, strides=strides, activation='relu', input_shape=(64, 64, 1)))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # TensorBoard log\n",
    "    log_dir = \"logs/fit/\" + \"conv_layers\" + str(conv_layers) + \"use_batch_norm=\" + str(use_batch_norm) + \"dropout_rate\" + str(dropout_rate) + \"padding\" + str(padding) + \"strides\" + str(strides)\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Навчання базової моделі з одним згортковим шаром\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64, callbacks=[tensorboard_callback])\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Експеримент 1: Різні параметри padding і strides\n",
    "params = [\n",
    "    {'padding': 'valid', 'strides': (1, 1)},\n",
    "    {'padding': 'same', 'strides': (1, 1)},\n",
    "    {'padding': 'same', 'strides': (2, 2)},\n",
    "]\n",
    "\n",
    "for param in params:\n",
    "    print(f\"Experiment with padding={param['padding']} and strides={param['strides']}\")\n",
    "    model, history = build_and_train_model_2(padding=param['padding'], strides=param['strides'])\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f'Validation accuracy: {val_acc:.4f}\\n')\n",
    "\n",
    "# Експеримент 2: Альтернативні архітектури з різними кількостями згорткових шарів, нормалізацією та дропаутом\n",
    "architectures = [\n",
    "    {'conv_layers': 2, 'use_batch_norm': False, 'dropout_rate': 0.0},\n",
    "    {'conv_layers': 3, 'use_batch_norm': True, 'dropout_rate': 0.2},\n",
    "    {'conv_layers': 3, 'use_batch_norm': True, 'dropout_rate': 0.5},\n",
    "]\n",
    "\n",
    "for arch in architectures:\n",
    "    print(f\"Experiment with conv_layers={arch['conv_layers']}, use_batch_norm={arch['use_batch_norm']}, dropout_rate={arch['dropout_rate']}\")\n",
    "    model, history = build_and_train_model_2(conv_layers=arch['conv_layers'], use_batch_norm=arch['use_batch_norm'], dropout_rate=arch['dropout_rate'])\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f'Validation accuracy: {val_acc:.4f}\\n')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:52:12.388649Z",
     "start_time": "2025-03-17T10:44:22.326069Z"
    }
   },
   "id": "f1818dd745125809"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Бачимо, що параметри згортки не сильно впливають на якість моделі, в цілому всі підходять. Використаємо базові padding='valid', strides=(1, 1). Після єкспериментів з моделямі найкращим варіантом виявився при трьох згорткових шарах, use_batch_norm=True, dropout_rate=0.2."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ab129f77844325"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Натренуємо таку модель і подивимося метрики на тестовому сеті"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bc936afcc8b82f7"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:52:12.522362Z",
     "start_time": "2025-03-17T10:52:04.755096Z"
    }
   },
   "id": "bc3081656640554a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 14s 90ms/step - loss: 1.1226 - accuracy: 0.6507 - val_loss: 0.4329 - val_accuracy: 0.8608\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.2532 - accuracy: 0.9169 - val_loss: 0.1852 - val_accuracy: 0.9488\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.1190 - accuracy: 0.9640 - val_loss: 0.1160 - val_accuracy: 0.9708\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.0699 - accuracy: 0.9785 - val_loss: 0.1558 - val_accuracy: 0.9513\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.0479 - accuracy: 0.9860 - val_loss: 0.0748 - val_accuracy: 0.9825\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.0358 - accuracy: 0.9897 - val_loss: 0.1015 - val_accuracy: 0.9754\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 0.0840 - val_accuracy: 0.9800\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.0942 - val_accuracy: 0.9787\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.0265 - accuracy: 0.9924 - val_loss: 0.0981 - val_accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.0229 - accuracy: 0.9934 - val_loss: 0.1000 - val_accuracy: 0.9754\n",
      "Test accuracy: 0.9800\n",
      "94/94 [==============================] - 1s 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       200\n",
      "           1     0.9803    0.9950    0.9876       200\n",
      "           2     0.9754    0.9900    0.9826       200\n",
      "           3     0.9548    0.9500    0.9524       200\n",
      "           4     0.9898    0.9700    0.9798       200\n",
      "           5     0.9844    0.9450    0.9643       200\n",
      "           6     0.9476    0.9950    0.9707       200\n",
      "           7     0.9802    0.9900    0.9851       200\n",
      "           8     1.0000    0.9800    0.9899       200\n",
      "           9     0.9949    0.9700    0.9823       200\n",
      "          10     0.9659    0.9900    0.9778       200\n",
      "          11     0.9949    0.9700    0.9823       200\n",
      "          12     0.9752    0.9850    0.9801       200\n",
      "          13     0.9652    0.9700    0.9676       200\n",
      "          14     0.9950    1.0000    0.9975       200\n",
      "\n",
      "    accuracy                         0.9800      3000\n",
      "   macro avg     0.9802    0.9800    0.9800      3000\n",
      "weighted avg     0.9802    0.9800    0.9800      3000\n",
      "\n",
      "AUC: 0.9998\n"
     ]
    }
   ],
   "source": [
    "best_model = build_and_train_model_2(conv_layers=3, use_batch_norm=True, dropout_rate=0.2, padding='valid', strides=(1,1))[0]\n",
    "\n",
    "# Оцінка на тестовій множині\n",
    "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Отримання метрик на тестовій множині\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes, digits=4))\n",
    "print(f\"AUC: {roc_auc_score(y_test, y_pred, multi_class='ovr'):.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:54:01.119587Z",
     "start_time": "2025-03-17T10:52:04.822828Z"
    }
   },
   "id": "dbc9088684317bc"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-5b459a664c4cdf31\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-5b459a664c4cdf31\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:54:01.145625Z",
     "start_time": "2025-03-17T10:53:58.806413Z"
    }
   },
   "id": "368b607efe69fc4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Отримали дуже високі метрики на тестовій множині - практично ідеальна модель. Якщо порiвнювати побудовану згорткову модель та багатошаровий персептрон в попередньому КП, такий варіант буде набагато кращий по всім параметрам. Це і логічно, без згорткових шарів точність класифікації навряд чи можна довести до якихось високих значень"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "410ca473af260ce9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Висновок - отримали високу якість класифікації з моделями зі згортковими шарами. В порівнянні з моделями без згорткових шарів, вони є набагато ефективнішими, тому в класифікації будь-яких зображень спроба використати згорткові шари - гарна ідея."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c1e644e03e9b05c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T10:54:01.145830Z",
     "start_time": "2025-03-17T10:53:58.812220Z"
    }
   },
   "id": "6b1e4a20bf46a6d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
