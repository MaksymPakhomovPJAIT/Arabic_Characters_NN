{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Arabic Characters Recognition Using Convolutional Neural Network"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fae1c71af2bd876e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "329d817bd0805b0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This project focuses on training a Convolutional Neural Network (CNN) to recognize Arabic handwritten characters. Handwritten character recognition is a crucial task in optical character recognition (OCR), with applications in document digitization, automated data entry, and assistive technologies.\n",
    "\n",
    "Arabic script poses unique challenges due to its cursive nature, varying character shapes based on position in a word, and high inter-class similarity. To tackle this, we utilize deep learning, leveraging CNNs for their ability to automatically extract features from images and learn hierarchical patterns.\n",
    "\n",
    "In this notebook, I will:\n",
    "\n",
    "Load and preprocess an Arabic handwritten character dataset.\n",
    "Build and train a CNN model for classification.\n",
    "Evaluate performance using accuracy and loss metrics.\n",
    "Analyse and tune the hyperparameters to build the best model possible.\n",
    "Visualize training process using TensorBoard\n",
    "This project aims to improve handwritten Arabic text recognition, demonstrating the power of deep learning in solving real-world OCR challenges"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3944b97123cb554d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the basic model with one convolutional layer and tuning hyperparameters:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "445014f81ef2fc6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data was taken from Kaggle:  https://www.kaggle.com/datasets/mloey1/ahcd1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "194b77a84c4f9fdc"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with padding=valid and strides=(1, 1)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 13:09:58.163428: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/168 [==============================] - 2s 12ms/step - loss: 3.5405 - accuracy: 0.1984 - val_loss: 2.2645 - val_accuracy: 0.3188\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 1.6643 - accuracy: 0.4798 - val_loss: 1.3366 - val_accuracy: 0.5781\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.9503 - accuracy: 0.6837 - val_loss: 0.9797 - val_accuracy: 0.6853\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.5659 - accuracy: 0.8108 - val_loss: 0.8989 - val_accuracy: 0.7314\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.3624 - accuracy: 0.8770 - val_loss: 0.8826 - val_accuracy: 0.7500\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.2515 - accuracy: 0.9182 - val_loss: 0.8609 - val_accuracy: 0.7705\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.1669 - accuracy: 0.9462 - val_loss: 0.8850 - val_accuracy: 0.7656\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.1200 - accuracy: 0.9644 - val_loss: 0.8812 - val_accuracy: 0.7853\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 2s 12ms/step - loss: 0.0855 - accuracy: 0.9748 - val_loss: 0.9626 - val_accuracy: 0.7831\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.0580 - accuracy: 0.9847 - val_loss: 1.0436 - val_accuracy: 0.7738\n",
      "Validation accuracy: 0.7738\n",
      "\n",
      "Experiment with padding=same and strides=(1, 1)\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 3s 14ms/step - loss: 3.7722 - accuracy: 0.1441 - val_loss: 2.6640 - val_accuracy: 0.2310\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 2.2858 - accuracy: 0.3208 - val_loss: 2.0742 - val_accuracy: 0.3668\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 1.5987 - accuracy: 0.4905 - val_loss: 1.3722 - val_accuracy: 0.5685\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.9509 - accuracy: 0.6880 - val_loss: 0.9810 - val_accuracy: 0.6804\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.5606 - accuracy: 0.8105 - val_loss: 0.8496 - val_accuracy: 0.7284\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 2s 15ms/step - loss: 0.3726 - accuracy: 0.8730 - val_loss: 0.8455 - val_accuracy: 0.7519\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.2426 - accuracy: 0.9196 - val_loss: 0.8832 - val_accuracy: 0.7541\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.1564 - accuracy: 0.9500 - val_loss: 0.8652 - val_accuracy: 0.7742\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.1016 - accuracy: 0.9692 - val_loss: 0.9696 - val_accuracy: 0.7679\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.0764 - accuracy: 0.9786 - val_loss: 1.0366 - val_accuracy: 0.7638\n",
      "Validation accuracy: 0.7638\n",
      "\n",
      "Experiment with padding=same and strides=(2, 2)\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 3.8485 - accuracy: 0.2165 - val_loss: 2.2504 - val_accuracy: 0.3397\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 1s 6ms/step - loss: 1.7086 - accuracy: 0.4680 - val_loss: 1.4499 - val_accuracy: 0.5402\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 1.0409 - accuracy: 0.6563 - val_loss: 1.2045 - val_accuracy: 0.6220\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.6851 - accuracy: 0.7680 - val_loss: 1.0626 - val_accuracy: 0.6797\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.4901 - accuracy: 0.8326 - val_loss: 1.0046 - val_accuracy: 0.7087\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.3494 - accuracy: 0.8815 - val_loss: 0.9513 - val_accuracy: 0.7340\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.2393 - accuracy: 0.9194 - val_loss: 1.0249 - val_accuracy: 0.7333\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.1712 - accuracy: 0.9446 - val_loss: 1.0782 - val_accuracy: 0.7310\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.1265 - accuracy: 0.9590 - val_loss: 1.0866 - val_accuracy: 0.7511\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 1s 5ms/step - loss: 0.0888 - accuracy: 0.9740 - val_loss: 1.1746 - val_accuracy: 0.7433\n",
      "Validation accuracy: 0.7433\n",
      "\n",
      "Experiment with conv_layers=2, use_batch_norm=False, dropout_rate=0.0\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 3.6473 - accuracy: 0.3093 - val_loss: 1.4169 - val_accuracy: 0.5599\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.9836 - accuracy: 0.6869 - val_loss: 0.8548 - val_accuracy: 0.7176\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.5415 - accuracy: 0.8288 - val_loss: 0.6228 - val_accuracy: 0.7965\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.3382 - accuracy: 0.8867 - val_loss: 0.5437 - val_accuracy: 0.8251\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.2087 - accuracy: 0.9313 - val_loss: 0.5653 - val_accuracy: 0.8359\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.1412 - accuracy: 0.9530 - val_loss: 0.5606 - val_accuracy: 0.8531\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 2s 14ms/step - loss: 0.0999 - accuracy: 0.9668 - val_loss: 0.6388 - val_accuracy: 0.8423\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 3s 15ms/step - loss: 0.0840 - accuracy: 0.9720 - val_loss: 0.5319 - val_accuracy: 0.8586\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.0571 - accuracy: 0.9820 - val_loss: 0.5860 - val_accuracy: 0.8635\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 2s 13ms/step - loss: 0.0488 - accuracy: 0.9834 - val_loss: 0.6022 - val_accuracy: 0.8650\n",
      "Validation accuracy: 0.8650\n",
      "\n",
      "Experiment with conv_layers=3, use_batch_norm=True, dropout_rate=0.2\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 4s 20ms/step - loss: 2.0569 - accuracy: 0.3925 - val_loss: 1.1664 - val_accuracy: 0.6105\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.8208 - accuracy: 0.7326 - val_loss: 0.5980 - val_accuracy: 0.7950\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 3s 21ms/step - loss: 0.5363 - accuracy: 0.8266 - val_loss: 0.4283 - val_accuracy: 0.8527\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.3762 - accuracy: 0.8781 - val_loss: 0.3417 - val_accuracy: 0.8876\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 4s 23ms/step - loss: 0.2902 - accuracy: 0.9076 - val_loss: 0.2902 - val_accuracy: 0.8996\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 4s 21ms/step - loss: 0.2309 - accuracy: 0.9272 - val_loss: 0.2346 - val_accuracy: 0.9159\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 4s 22ms/step - loss: 0.1872 - accuracy: 0.9399 - val_loss: 0.3123 - val_accuracy: 0.8925\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 3s 21ms/step - loss: 0.1639 - accuracy: 0.9475 - val_loss: 0.2361 - val_accuracy: 0.9182\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.1364 - accuracy: 0.9532 - val_loss: 0.2334 - val_accuracy: 0.9219\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.1209 - accuracy: 0.9608 - val_loss: 0.2457 - val_accuracy: 0.9211\n",
      "Validation accuracy: 0.9211\n",
      "\n",
      "Experiment with conv_layers=3, use_batch_norm=True, dropout_rate=0.5\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 4s 23ms/step - loss: 2.5454 - accuracy: 0.2662 - val_loss: 1.4175 - val_accuracy: 0.5413\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 4s 22ms/step - loss: 1.2756 - accuracy: 0.5846 - val_loss: 0.6996 - val_accuracy: 0.7868\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 4s 24ms/step - loss: 0.8409 - accuracy: 0.7259 - val_loss: 0.5046 - val_accuracy: 0.8441\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 4s 22ms/step - loss: 0.6262 - accuracy: 0.7943 - val_loss: 0.4360 - val_accuracy: 0.8497\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 4s 22ms/step - loss: 0.4957 - accuracy: 0.8398 - val_loss: 0.3410 - val_accuracy: 0.8925\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 3s 20ms/step - loss: 0.4191 - accuracy: 0.8664 - val_loss: 0.3099 - val_accuracy: 0.9007\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.3413 - accuracy: 0.8889 - val_loss: 0.2691 - val_accuracy: 0.9096\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 3s 19ms/step - loss: 0.3114 - accuracy: 0.8982 - val_loss: 0.2581 - val_accuracy: 0.9152\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 4s 21ms/step - loss: 0.2707 - accuracy: 0.9109 - val_loss: 0.2786 - val_accuracy: 0.9036\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 3s 21ms/step - loss: 0.2459 - accuracy: 0.9214 - val_loss: 0.1980 - val_accuracy: 0.9371\n",
      "Validation accuracy: 0.9371\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# Importing data\n",
    "train_images = pd.read_csv('archive/csvTrainImages 13440x1024.csv', header=None)\n",
    "train_labels = pd.read_csv('archive/csvTrainLabel 13440x1.csv', header=None)\n",
    "test_images = pd.read_csv('archive/csvTestImages 3360x1024.csv', header=None)\n",
    "test_labels = pd.read_csv('archive/csvTestLabel 3360x1.csv', header=None)\n",
    "\n",
    "# Data preparation\n",
    "train_images = train_images.values.reshape(-1, 32, 32, 1).astype('float32')\n",
    "test_images = test_images.values.reshape(-1, 32, 32, 1).astype('float32')\n",
    "\n",
    "train_labels -= 1\n",
    "test_labels -= 1\n",
    "\n",
    "\n",
    "num_classes = 28 \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
    "\n",
    "# Splitting data into train/test\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function for building and training the model\n",
    "def build_and_train_model(conv_layers=1, filters=32, kernel_size=(3, 3), padding='valid', strides=(1, 1),\n",
    "                          use_batch_norm=False, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "\n",
    "    \n",
    "    for _ in range(conv_layers):\n",
    "        model.add(Conv2D(filters, kernel_size=kernel_size, padding=padding, strides=strides, activation='relu', input_shape=(32, 32, 1)))\n",
    "        if use_batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # TensorBoard log\n",
    "    log_dir = \"logs/fit/\" + \"conv_layers\" + str(conv_layers) + \"use_batch_norm=\" + str(use_batch_norm) + \"dropout_rate\" + str(dropout_rate) + \"padding\" + str(padding) + \"strides\" + str(strides)\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Training a base model with 1 convolutional layer\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64, callbacks=[tensorboard_callback])\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Experiment 1: Different padding and strides\n",
    "params = [\n",
    "    {'padding': 'valid', 'strides': (1, 1)},\n",
    "    {'padding': 'same', 'strides': (1, 1)},\n",
    "    {'padding': 'same', 'strides': (2, 2)},\n",
    "]\n",
    "\n",
    "for param in params:\n",
    "    print(f\"Experiment with padding={param['padding']} and strides={param['strides']}\")\n",
    "    model, history = build_and_train_model(padding=param['padding'], strides=param['strides'])\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f'Validation accuracy: {val_acc:.4f}\\n')\n",
    "\n",
    "# Experiment 2: Alternative structures with different numbers of convolutional layers, normalisation and dropout\n",
    "architectures = [\n",
    "    {'conv_layers': 2, 'use_batch_norm': False, 'dropout_rate': 0.0},\n",
    "    {'conv_layers': 3, 'use_batch_norm': True, 'dropout_rate': 0.2},\n",
    "    {'conv_layers': 3, 'use_batch_norm': True, 'dropout_rate': 0.5},\n",
    "]\n",
    "\n",
    "for arch in architectures:\n",
    "    print(f\"Experiment with conv_layers={arch['conv_layers']}, use_batch_norm={arch['use_batch_norm']}, dropout_rate={arch['dropout_rate']}\")\n",
    "    model, history = build_and_train_model(conv_layers=arch['conv_layers'], use_batch_norm=arch['use_batch_norm'], dropout_rate=arch['dropout_rate'])\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f'Validation accuracy: {val_acc:.4f}\\n')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T12:12:30.941876Z",
     "start_time": "2025-03-17T12:09:55.056540Z"
    }
   },
   "id": "5ec6b7225bdd98a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the best result in terms of metrics is the one with padding=same, strides=(1,1). This model has an accuracy of roughly 78%.\n",
    "Also after analysis of parameters and convolutional numbers analysis we can see that best parameters are 3 conv layers, 'use_batch_norm': True, 'dropout_rate': 0.2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7f6ad444f131aaf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's train such model and check the results for each class (letter):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68afc3cfb4f7ef02"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T12:12:31.087990Z",
     "start_time": "2025-03-17T12:12:30.941Z"
    }
   },
   "id": "b8c6ca8125037377"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "168/168 [==============================] - 5s 26ms/step - loss: 1.9282 - accuracy: 0.4341 - val_loss: 0.8810 - val_accuracy: 0.7251\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 4s 25ms/step - loss: 0.6772 - accuracy: 0.7797 - val_loss: 0.4955 - val_accuracy: 0.8445\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.3931 - accuracy: 0.8713 - val_loss: 0.3680 - val_accuracy: 0.8713\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 4s 27ms/step - loss: 0.2663 - accuracy: 0.9146 - val_loss: 0.2539 - val_accuracy: 0.9156\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.1984 - accuracy: 0.9354 - val_loss: 0.2450 - val_accuracy: 0.9226\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 5s 28ms/step - loss: 0.1570 - accuracy: 0.9488 - val_loss: 0.2580 - val_accuracy: 0.9163\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 5s 29ms/step - loss: 0.1215 - accuracy: 0.9610 - val_loss: 0.2424 - val_accuracy: 0.9189\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 4s 27ms/step - loss: 0.0971 - accuracy: 0.9680 - val_loss: 0.2078 - val_accuracy: 0.9382\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 4s 26ms/step - loss: 0.0836 - accuracy: 0.9726 - val_loss: 0.2132 - val_accuracy: 0.9334\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 5s 28ms/step - loss: 0.0701 - accuracy: 0.9764 - val_loss: 0.2016 - val_accuracy: 0.9364\n",
      "Test accuracy: 0.9411\n",
      "105/105 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    1.0000    0.9756       120\n",
      "           1     0.9440    0.9833    0.9633       120\n",
      "           2     0.9492    0.9333    0.9412       120\n",
      "           3     0.9561    0.9083    0.9316       120\n",
      "           4     0.9741    0.9417    0.9576       120\n",
      "           5     0.8855    0.9667    0.9243       120\n",
      "           6     0.9658    0.9417    0.9536       120\n",
      "           7     0.8943    0.9167    0.9053       120\n",
      "           8     0.9541    0.8667    0.9083       120\n",
      "           9     0.8872    0.9833    0.9328       120\n",
      "          10     0.9304    0.8917    0.9106       120\n",
      "          11     0.9820    0.9083    0.9437       120\n",
      "          12     0.9828    0.9500    0.9661       120\n",
      "          13     0.8872    0.9833    0.9328       120\n",
      "          14     0.9737    0.9250    0.9487       120\n",
      "          15     0.9077    0.9833    0.9440       120\n",
      "          16     0.9328    0.9250    0.9289       120\n",
      "          17     0.9658    0.9417    0.9536       120\n",
      "          18     0.9831    0.9667    0.9748       120\n",
      "          19     0.9024    0.9250    0.9136       120\n",
      "          20     0.9439    0.8417    0.8899       120\n",
      "          21     0.9735    0.9167    0.9442       120\n",
      "          22     0.9225    0.9917    0.9558       120\n",
      "          23     1.0000    0.9667    0.9831       120\n",
      "          24     0.8672    0.9250    0.8952       120\n",
      "          25     0.9664    0.9583    0.9623       120\n",
      "          26     0.9573    0.9333    0.9451       120\n",
      "          27     0.9512    0.9750    0.9630       120\n",
      "\n",
      "    accuracy                         0.9411      3360\n",
      "   macro avg     0.9426    0.9411    0.9410      3360\n",
      "weighted avg     0.9426    0.9411    0.9410      3360\n",
      "\n",
      "AUC: 0.9991\n"
     ]
    }
   ],
   "source": [
    "best_model = build_and_train_model(conv_layers=3, use_batch_norm=True, dropout_rate=0.2, padding='same', strides=(1,1))[0]\n",
    "\n",
    "# Evalutating\n",
    "test_loss, test_acc = best_model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Getting metrics\n",
    "y_pred = best_model.predict(test_images)\n",
    "y_true = np.argmax(test_labels, axis=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes, digits=4))\n",
    "print(f\"AUC: {roc_auc_score(test_labels, y_pred, multi_class='ovr'):.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T12:13:18.962722Z",
     "start_time": "2025-03-17T12:12:31.092842Z"
    }
   },
   "id": "d827f305ff986779"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For all 28 classes we've got great metrics - good result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "957d626347bd9891"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T12:13:18.963030Z",
     "start_time": "2025-03-17T12:13:18.792780Z"
    }
   },
   "id": "4480d2f0048e5f85"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualisation of training in TensorBoard"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ac8fcf0d1610f31"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-33d6a9dfda7f60b7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-33d6a9dfda7f60b7\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-17T12:13:18.963782Z",
     "start_time": "2025-03-17T12:13:18.799300Z"
    }
   },
   "id": "b6431eb0d6211f47"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
